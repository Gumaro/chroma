\documentclass[12pt]{article}
\usepackage{fullpage}
\usepackage{times}
\usepackage{html}
\title{Notes on the Partial Fraction 5D operator}
\author{B\'alint Jo\'o}
\begin{document}
\maketitle
\newcommand{\gf}{\ensuremath{\gamma_5}}
\newcommand{\eps}{\ensuremath{\varepsilon}}
\abstract{ }
\section{Introduction}
The partial fraction operator was introduced by Neuberger and Narayanan
in their paper {\em ``An Alternative to Domain Wall Fermions''}
 \cite{NeubergerNarayanan}. In this note
\begin{itemize}
  \item
    We will generalise the operator to arbitrary rational approximations.
We will show how it can be adapted to the general Moebius kernel (rather
than just the Wilson-Overlap kernel). We identify a way to tune 
the operator that is similar to the one employed for Continued Fractions.
  \item
    We will show how the operator reduces to the effective 4D theory, by 
block diagonalisation. We will identify the bulk determinant (so called
Pauli-Villars determinant) and discuss its cancellation.
  \item
    We discuss a 4D even-odd preconditioning strategy for the operator.
\end{itemize}

\section{The Operator}
Neuberger and Narayanan's original operator was written as
\begin{equation}
H = \left( \begin{array}{cccccccc} 
-\frac{1+\mu}{2}\gf & \sqrt{\frac{1-\mu}{2n}} & 0 & \sqrt{\frac{1-\mu}{2n}} & 0  & \ldots & \sqrt{\frac{1-\mu}{2n}} & 0 \\
\sqrt{\frac{1-\mu}{2n}} & c_1^2 H_W & s_1 &  0 & 0& \ldots & 0 & 0\\
          0            &   s_1     & -H_W &  0 & 0& \ldots & 0 & 0\\
\sqrt{\frac{1-\mu}{2n}} &     0    &  0  & c_2^2 H_W & s_2  & \ldots & 0 & 0 \\
          0             &     0    &  0  & s_2       & -H_W & \ldots & 0 & 0 \\
       \vdots           &   \vdots & \vdots & \vdots & \vdots & \vdots & 0 & 0 \\
\sqrt{\frac{1-\mu}{2n}} &     0    &  0 &  0         & 0     & \ldots & c_n^2 H_W & s_n \\
         0              &     0    &  0 &  0         &  0    & \ldots & s_{n} & -H_W \\
\end{array} \right)
\end{equation}
where $\mu$ is the quark mass ($0 \le \mu < 1$), $n$ is the number of terms
in the partial fraction approximation to the sign function, and $c_{i}$ and $s_i$ are coefficients fo the partial fraction approximation. The operator $H_W$ is
the hermitian Wilson Dirac operator with large negative mass as usual:
\begin{eqnarray}
H_W &=& \gf D_W = D_W^{\dagger} \gf = H_W^{\dagger}\\
D_W &=& (N_d - M) - \frac{1}{2} D_s
\end{eqnarray}
with $N_d$ being the number of spacetime dimensions, $M$ being the 
``negative'' mass (the minus sign is explicit in the definition of $D_W$
above to make $M$ positive), and $D_s$ is the Wilson Dslash operator.

The coefficients are defined as: 
\begin{equation}
c_s = \cos \theta_s,\  s_s = \sin \theta_s, \ \theta_s = \frac{\pi}{2n}(s - \frac{1}{2}), s = 1, 2, \ldots, n
\end{equation}
and define a rational approximation to the matrix sign function $\eps_{n}(H_W)$:
\begin{equation}
\eps_{n}(H_W) = \frac{1}{n}\sum_{s=1}^{n} \frac{1}{c_s^2 H_W + \frac{\displaystyle s_s^s}{\displaystyle H_W}}
\end{equation}

Introducing fermion fields $\Psi = (\psi_0, \psi_1, \psi_2, \ldots, \psi_{2n} )^T$ and $\bar{\Psi} = (\bar{\psi_0}, \bar{\psi_1}, \bar{\psi_2}, \ldots, \bar{\psi_{2n}} )$, one can write the partition function
\begin{equation}
\int d \bar{\Psi} d\Psi e^{\bar{\Psi} H \Psi}  = \left[ \prod_{s=1}^{n} \det( c_s^2 H_W^2 + s_s^2 ) \right] 
\int d\psi_0 d \bar{\psi_0}
 e^{ -\bar{\psi_0} \left( \frac{1+\mu}{2} \gf + \frac{1-\mu}{2} \eps_{n} (H_W) \right) \psi_0} \ .
\end{equation} 
Here the product of determinants comes from integrating out the extraneous fermion fields: $\bar{\psi_{i}},\psi_{i}, i=1,\ldots 2n$. We will show a way to do this explictly later. This product of determinants is the so called ``bulk determinant''. It is also colloquially called Pauli-Villars determinant. In a simulation
these determinants would need to be cancelled to get the correct
distribution for the required 4D chiral operator.

We note in passing that in the above, we neglected the question of the 
action being positive definite. Manifest positivity  can always be
achieved by using the square of the action (2 flavour simulation).
For one flavour simulations, one can always attempt to take the square
root of the two flavour action.

The construction is completed by showing that as $n\rightarrow \infty$, 
$\eps_{n}(H_W) \rightarrow {\rm sign}(H_W)$, implying that in the limit
of the fifth dimension becoming infinite we have a partition function whose
action is defined by the Hermitian form of the overlap operator:
\begin{equation}
-\bar{\psi_0} H_{ov}^{H}\psi_0 = -\bar{\psi_0} \left( \frac{1+\mu}{2}\gf + \frac{1-\mu}{2} {\rm sign}(H_W) \right) \psi_0
\end{equation}

As $n \rightarrow \infty$, the discrete $\theta_s$ above become a continuum, and the sum over the $\theta_{s}$ becomes an integral with respect to $\theta$. The integral measure is $d\theta = \frac{\pi}{2n} ds$ from the 
above definition of $\theta_s$.  The sum in the definition of $\eps_{n}(H_W)$ is written as an integral
\begin{equation} 
\eps_{n}(H_W) = \frac{1}{n}\sum_{s=1}^{n} \frac{1}{c_s^2 H_W + \frac{\displaystyle s_s^s}{\displaystyle H_W}} \rightarrow \frac{2}{\pi}\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{ H_W \cos^2 \theta + \frac{\displaystyle \sin^2 \theta }{\displaystyle H_W}}  \ .
\end{equation}
One then makes the substitution: $t = \tan \theta$. The measure changes
to $ dt = \frac{d\theta}{\cos^2 \theta} $. The limits of the integral
change from $(0, \frac{\pi}{2})$ to $(0, \infty)$ and the integral becomes:
\begin{equation}
\eps_{ n\rightarrow \infty }(H_W) =   \frac{2}{\pi}\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{ H_W \cos^2 \theta + \frac{\displaystyle \sin^2 \theta }{\displaystyle H_W}} = \frac{2}{\pi} \int_{0}^{\infty} \frac{dt}{t} \ \frac{1}{\frac{\displaystyle H_W}{\displaystyle t} + \frac{\displaystyle t}{\displaystyle H_W} } = {\rm sign}(H_W)
\end{equation}

\section{Block Diagonalisation by Schur Decomposition}
We will now performa a block diagonalisation of $H$ by using the Schur decomposition. Consider a matrix 
\begin{equation}
M = 
\left( \begin{array}{cc}
A & B \\
C & D 
\end{array}
\right)
\end{equation}
where $A$, $B$, $C$ and $D$ are submatrices. In particular $M$ is an $n \times n$ with $n \ge 2$ matrix and $A$ is an $ m \times m$ matrix with $1 \le m < n$, 
$B$ and $C$ are matrices of size $(n-m) \times m$ and $m \times (n-m)$ respectively. We also assume that $A$ is invertible. The Schur decomposition of $M$ is then 
\begin{eqnarray}
M &=& L \tilde{D} U \\
  &=& \left( 
\begin{array}{cc}
 1 & 0 \\
C A^{-1} & 1 
\end{array} \right)
\ \left( \begin{array}{cc}
  A & 0 \\
  0 & S \\
\end{array} \right) 
\ \left( \begin{array}{cc}
  1 & A^{-1} B \\
  0 &  1  \\
\end{array} \right)
\end{eqnarray}
where $S$ is called the Schur's complement matrix defined as:
\begin{equation}
S = D - C A^{-1} B
\end{equation}
and we identify the lower an upper triangular matrices
\begin{equation} \label{eq:LDU1}
L = \left( 
\begin{array}{cc}
 1 & 0 \\
C A^{-1} & 1 
\end{array} \right) \quad
U =  \left( \begin{array}{cc}
  1 & A^{-1} B \\
  0 &  1  \\
\end{array} \right)
\end{equation}
and a block diagonal matrix
\begin{equation} \label{eq:LDU2}
\tilde{D} = \left( \begin{array}{cc}
  A & 0 \\
  0 & S \\
\end{array} \right) \ .
\end{equation}

Clearly, $\det(L)=\det(U)=1$ and  
\begin{equation}
\det(M) = \det(\tilde{D}) = \det(A) \det(S) \ .
\end{equation}

We will now proceed to perform the Schur decomposition of our operator. We will
\begin{itemize}
\item
  show that the desired chiral operator is the Schur's complement of the matrix $H$ under a particular decomposition.
\item
  show how the bulk determinant arises .
\end{itemize}

To make the situation explicit for the case of our operator, we rewrite it, reversing the order of the rows and the order of the columns (and likewise the order of the corresponding fields in the action), and identify the submatrices of interest:
\begin{equation}
H = 
\left( \begin{array}{ccccccc|c} 
-H_W & s_n &       \ldots & 0 & 0 & 0& 0 & 0 \\
s_n  & c_n^2 H_W & \ldots & 0 & 0 & 0& 0 & \sqrt{ \frac{1-\mu}{2n} } \\
 0   &   0       & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0   &   0       & \ldots &  -H_W  &  s_2   &   0    &    0   &   0    \\
 0   &   0       & \ldots & s_2  & c_2^2 H_W &  0    &    0   &  \sqrt{ \frac{1-\mu}{2n} } \\
 0   &   0       & \ldots &    0   &    0    &  -H_W &  s_1   &    0   \\
 0   &   0       & \ldots &    0   &    0    &  s_1  & c_1^2 H_W &  \sqrt{ \frac{1-\mu}{2n} } \\ 
\hline 0   &  \sqrt{ \frac{1-\mu}{2n} } &  \ldots & 0 &  \sqrt{ \frac{1-\mu}{2n} } & 0 &  \sqrt{ \frac{1-\mu}{2n} } & -\frac{1+\mu}{2} \gf 
\end{array} \right)
\end{equation}

We make the identifications, as suggested by the partitioning lines above,  that 
\begin{eqnarray}
A &=&  
\left( \begin{array}{ccccccc} 
-H_W & s_n &       \ldots & 0 & 0 & 0& 0 \\
s_n  & c_n^2 H_W & \ldots & 0 & 0 & 0& 0 \\
 0   &   0       & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0   &   0       & \ldots &  -H_W  &  s_2   &   0    &    0   \\
 0   &   0       & \ldots & s_2  & c_2^2 H_W &  0    &    0   \\
 0   &   0       & \ldots &    0   &    0    &  -H_W &  s_1   \\
 0   &   0       & \ldots &    0   &    0    &  s_1  & c_1^2 H_W
\end{array} \right) \\
 C &=& B^{T} = \left( 0, \sqrt{\frac{1-\mu}{2n}}, \ldots, 0, \sqrt{\frac{1-\mu}{2n}}, 0 , \sqrt{ \frac{1-\mu}{2n} } \right) \\
 D &=& -\frac{1+\mu}{2}\gf 
\end{eqnarray}
The Schur's complement is: 
\begin{equation}
S = D - C A^{-1} B \ .
\end{equation}
Let us now write A as 
\begin{equation}
A = \left( \begin{array}{cccc}
A_{n} & \ldots &  0  & 0 \\
  0   & \vdots & \vdots& \vdots \\
  0   & \ldots & A_2   &  0 \\
  0   & \ldots &  0    &  A_1
\end{array} \right)
\end{equation}
with sub-blocks:
\begin{equation}
A_{i} = \left( \begin{array}{cc}
-H_W & s_{i} \\
s_{i}& c_i^2 H_W
\end{array} \right) \ .
\end{equation}
Likewise, one can write 
\begin{equation}
C = B^{T} = \left( B_{n}^T, \ldots, B_{2}^T, B_{1}^T \right)
\end{equation}
with 
\begin{equation}
B_{i}^T = \left( 0, \sqrt{ \frac{1 -\mu}{2n}} \right) \ .
\end{equation}
The Schur Complement can then be written as:
\begin{equation}
S = D - \sum_{i=1}^{n} C_{i} A_{i}^{-1} B_{i}
\end{equation}
We can evaluate the terms in the sum easily:
\begin{equation}
C_{i} A^{-1} B_{i} = C_{i} X^{i},\quad  X^{i} = A_{i}^{-1} B_{i} \ .
\end{equation}
First we obtain $X^{i}$. It is the solution of $A_{i} X^{i} = B_{i}$.
We let $X^{i} = \left( X_{1}^{i}, X_{2}^{i} \right)^T$ and solve:
\begin{equation}
\left( \begin{array}{cc} 
-H_W & s_i \\
 s_i & c_i^2 H_W 
\end{array} \right)
\left( \begin{array}{c}
X_1^i \\
X_2^i \\
\end{array} \right) = \left( \begin{array}{c} 
0 \\
\sqrt{\frac{1-\mu}{2n}} 
\end{array} \right)
\end{equation}
We see that we have the simultaneous system:
\begin{eqnarray}
-H_W X_1^i + s_i X_2^i &=& 0  \label{eq:sim1} \\
s_i X_1^i + c_i^2 H_W X_1^i &=& \sqrt{\frac{1-\mu}{2n}} \label{eq:sim2} 
\end{eqnarray}
From eq. (\ref{eq:sim1}) we have that:
\begin{equation} 
-H_W X_1^i + s_i X_2^i = 0  \Rightarrow X_1^i = s_i H_W^{-1} X_2^{i}
\end{equation}
and subsituting this into eq. \ref{eq:sim2} we get:
\begin{eqnarray}
 s_i X_1^i + c_i^2 H_W X_2^i &=&  \sqrt{\frac{1-\mu}{2n}} \\
\Rightarrow  s_i^2 H_W^{-1} X_2^{i} +  c_i^2 H_W X_2^i &=& \sqrt{\frac{1-\mu}{2n}} \\
\Rightarrow ( s_i^2 H_W^{-1} + c_i^2 H_W ) X_2^i &=& \sqrt{\frac{1-\mu}{2n}} \\
\Rightarrow X_2^{i} &=&  ( s_i^2 H_W^{-1} + c_i^2 H_W )^{-1} \sqrt{\frac{1-\mu}{2n}} \\
\Rightarrow X_1^i &=& s_i H_W^{-1} X_2^i
\end{eqnarray}
Then we have 
\begin{eqnarray}
C_i A_{i}^{-1} B_i &=& C_i X^{i} \\
               &=& ( 0, \sqrt{\frac{1-\mu}{2n}} ) X^{i} \\ 
               &=& \sqrt{\frac{1-\mu}{2n}} X_2^i \\
               &=& \frac{1-\mu}{2n} \frac{1}{c_i^2 H_W + \frac{\displaystyle s_i^2}{\displaystyle H_W} }
\end{eqnarray}
and 
\begin{eqnarray}
S &=& D - \sum_{i=1}^{n} C_i A_i^{-1} B_{i} \\
  &=& -\frac{1+\mu}{2} \gf -  \frac{1-\mu}{2} \frac{1}{n} \sum_{i=1}^{n}  \frac{1}{c_i^2 H_W + \frac{\displaystyle s_i^2}{\displaystyle H_W} } \\
  &=& - \left( \frac{1+\mu}{2} + \frac{1-\mu}{2} \eps_{n}(H_w) \right) 
\end{eqnarray}

Finally we note that $\det(H) = \det(A) \det(S)$. The bulk determinant is 
none other than $\det(A)$:
\begin{equation}
\det(A) = \prod_{i=1}^{n} \det(A_i)
\end{equation}
with 
\begin{equation}
\det(A_i) = -c_i^{2} H_W^{2} - s_i^2 = -( c_i^2 H_W^2 + s_i^2 )
\end{equation}
and so
\begin{equation}
\det(A) = (-1)^{n} \prod_{i=1}^{n} ( c_i^2 H_W^2 + s_i^2 ) = \prod_{i=1}^{n} ( c_i^2 H_W^2 + s_i^2 ) \quad \mbox{for even $n$}
\end{equation}

We can now connect with the integration in \cite{NeubergerNarayanan}. We 
write $H = L \tilde{D} U$ with $L$, $\tilde{D}$ and $U$ defined as before with the matrices
$A, B, C$ and $D$. We write
\begin{equation}
\bar{\Psi} H \Psi = \bar{\Psi} L \tilde{D} U \Psi 
\end{equation}
and we change the variables to $\bar{\Omega}$ and $\Omega$
with 
\begin{equation} 
\Omega = U \Psi, \quad \bar{\Omega} = \bar{\Psi} L \ .
\end{equation}
giving 
\begin{equation}
\bar{\Psi} H \Psi = \bar{\Psi} L \tilde{D} U \Psi = \bar{\Omega} \tilde{D} \Omega \ .
\end{equation}
This change of variables does not change the integration measure since
$\det(U) = \det(L) = 1$. We now integrate out all the fields corresponding
to the $A$ block in $\tilde{D}$ resulting in the bulk determinant:
\begin{eqnarray}
Z &=& \int d\bar{\Psi} d\Psi \  e^{\displaystyle \bar{\Psi} H \Psi} \\
  &=& \int d\bar{\Omega} d\Omega \ e^{\displaystyle \bar{\Omega} \tilde{D} \Omega } \\
  &=& (-1)^N \left[ \prod_{i} \det( c_i^2 H_W^2 + s_i^2 ) \right] \int d\bar{\omega}_0 d\omega_0 \  e^{\displaystyle \bar{\omega}_0  S  \omega_0 }
\end{eqnarray}

\subsection{Generalising the operator}
In \cite{NeubergerNarayanan} a particular approximation was chosen for the 
rational approximation employed in $H$, which is not necessarily the 
most optimal. Also the operator employed only the Wilson kernel $H_W$. 
None of these are concrete requirements. We will now generalise 
the operator $H$ for arbitrary rational approximations and for the 
full Moebius kernel.

To begin with we drop the subscript from $H_W$. From here on, it can 
be any kernel In order not to confuse the $H$ used for the kernel, 
we will refer to the generalised 5D operator as $M$ from here on. 
What kernel it actually is may affect the implemenation
and we will get back to that.

Secondly we consider an arbitrary approximation for the sign function:
\begin{equation}
\eps_{N}(H) = p_0 H + \sum_{i=1}^{N} \frac{ p_i H }{H^2 + q_i}
\end{equation}
where $n$ has been replaced with $N$. This is a general partial fraction
form for a rational polynomial with $N$ {\em poles}. We reserve $n$ for the
degree of the rational approximation. For a $(n-1, n)$ degree
rational approximation of $H^2$, the number of poles is $ n \over 2$. Further
for type 0 rational polynomials with $n$ even, we have that $p_0=0$.

Let us manipulate $\eps_{N}(H)$ a little:
\begin{eqnarray} 
\eps_{N}(H) &=& p_0 H + \sum_{i=1}^{N} \frac{H}{H} \frac{p_i}{H + \frac{\displaystyle q_i}{\displaystyle H}} \\
            &=& p_0 H + \sum_{i=1}^{N} \frac{p_i}{H + \frac{\displaystyle q_i}{\displaystyle H}} \\
            &=& p_0 H + \sum_{i=1}^{N} \frac{(1/\beta_i)}{(1/\beta_i)} \frac{ \beta_i p_i}{\beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H}}, \ \mbox{for nonzero constants}\  \beta_i  \\
 &=& p_0 H + \sum_{i=1}^{N} \frac{ \beta_i p_i}{\beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H}}
\end{eqnarray}

The constants $\beta_i$ can be arbitrary nonzero constants. They make no
difference to the final numerical results, but we can perhaps use them 
to tune the condition of the operator.

Secondly, let us move to the same operator normalisation as in our
continued fraction case and let 
\begin{equation}
H_{ov}(\mu) = R \gf + \eps_{N}(H)
\end{equation}
with 
\begin{equation}
R = \frac{1+\mu}{1-\mu} .
\end{equation}

Note that we have dropped the minus sign in the definition of $H_{ov}$
as opposed to the original operator. We prefer to write this explicitly
in the action, rather than to fold it into our new operator.

A bit of thought should show us the way to the generalised 5D operator,
if we think in terms of the $A$, $B$, $C$, $D$ block decomposition.
\begin{itemize} 
\item
The original operator had blocks $A_i$ corresponding to terms $\frac{1}{c^2H + \frac{s^2}{H}}$. Our new operator can have instead blocks corresponding to $\frac{1}{\beta_i H + \frac{\beta_i q_i}{H}}$ giving:
\begin{equation}
A_i = \left( \begin{array}{cc} 
 -H & \sqrt{\beta_i q_i} \\
\sqrt{\beta_i q_i} &  \beta H 
\end{array} \right) 
\end{equation}
\item
The matrices $B$ and $C$ in the original operator contained elements of the 
form $\sqrt{\frac{1-\mu}{2n}}$. The purpose of these was to fix the coupling 
of the $A_i^{-1}$ blocks to last component  to be $\frac{1-\mu}{2n}$ and thus 
provide the correct prefactor to the sum of poles. Our partial fraction does not contain the $\frac{1}{n}$ prefactor of the sum in $\eps(H)$ as before, so that can go. Also with
our change of normalisation there is no need for the $\frac{1-\mu}{2}$ 
terms. However we do need to couple each block $A_i$ into the Schur complement
with coupling $-\beta_i p_i$. The minus sign comes in because we have
removed the overall minus sign in the operator, and we now need to turn
the subtraction in the definition of the Schur's complement into an
addition. The $\beta_i p_i$ part just takes care of the numerator terms
in our new partial fraction expansion. This suggests that we should have $C_i = -B_i^{T}$ rather than $C_i = B_i^T$ as before to take care of the 
minus sign. Thus we choose
\begin{eqnarray}
B_{i} &=&  \left( 0,  \sqrt{ \beta_i p_i } \right)^{T} \\
C_{i} &=&  \left( 0, -\sqrt{ \beta_i p_i } \right) \ .
\end{eqnarray}
we note that with this new choice our operator will no longer be Hermitian.
Beforehands it used to be Hermitian but was not positive definite. Now
it is neither Hermitian nor positive definite. We could restore hermiticity
if we re-added the overall minus sign. We can also add the minus sign
to the blocks $A_i$, which would give us Hermiticity and $B_i^T=C_i$.
\item
Finally we consider $D$. Beforehands the sole purpose of $D$ was just
to catch the part of the 5D operator that we could not split into the 
5th dimension. This time round that would make
\begin{equation}
D = R \gf + p_0 H
\end{equation}
\end{itemize}

We can see how this will fit together.
\begin{equation}
S = D - C A^{-1} B = D - \sum_{i} C_i A_{i}^{-1} B_{i} 
\end{equation}
as before consider 
\begin{eqnarray}
X_2^{i} &=& A_{i}^{-1} B_{i} = \sqrt{\beta_i p_i} \left( \beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H} \right)^{-1} \\
C_i A_{i}^{-1} B_{i} &=&  C_{i} X^{i} = -\sqrt{\beta_i p_i} X_2^{i} = -\frac{\beta_i p_i}{  \beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H} } \\ 
S &=& D - CA^{-1}B =  D - \sum_{i} C_i A_{i}^{-1} B_{i} \\
&=& R\gf + p_0 H - \left( -\frac{\beta_i p_i}{  \beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H} } \right) \\ 
&=& R\gf + p_0 H + \frac{\beta_i p_i}{  \beta_i H + \frac{\displaystyle \beta_i q_i}{\displaystyle H} }
\end{eqnarray}

The operator in terms of $A_i, B_i, C_i$ and $D$ is then 
\begin{equation}
M = \left( \begin{array}{ccccc}
A_N & \ldots & 0 & 0 & B_N \\
0   &  \vdots & \vdots &\vdots & \vdots \\
0   & \ldots  & A_2 & 0 & B_2 \\
0   & \ldots  &  0  & A_1 & B_1 \\
C_N & \ldots  & C_2 & C_1 &  D  
\end{array} \right),\quad
M^{\dagger} = \left( \begin{array}{ccccc}
A_N & \ldots & 0 & 0 & C_N \\
0   &  \vdots & \vdots &\vdots & \vdots \\
0   & \ldots  & A_2 & 0 & C_2 \\
0   & \ldots  &  0  & A_1 & C_1 \\
B_N & \ldots  & B_2 & B_1 &  D  
\end{array} \right) 
\end{equation}
or in full
\begin{equation}
M = \left( \begin{array}{cccccccc}
-H & \sqrt{\beta_N q_N}& \ldots & 0 & 0 & 0 & 0 & 0 \\
\sqrt{\beta_N q_N} & \beta_N H & \ldots & 0 & 0 & 0& 0 & \sqrt{\beta_N p_N } \\
 0  &  0  &  \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0  &  0  & \ldots  & -H  & \sqrt{\beta_2 q_2} & 0 & 0 &  0 \\
 0  &  0  & \ldots  & \sqrt{\beta_2 q_2} & \beta_2 H & 0 & 0 & \sqrt{\beta_2 p_2} \\
 0  &  0  & \ldots &         0        &  0 & -H & \sqrt{\beta_1 q_1} & 0 \\
 0  &  0  & \ldots &         0        &  0 & \sqrt{\beta_1 q_1} & \beta_1 H & \sqrt{\beta_1 p_1} \\
 0  & -\sqrt{\beta_N p_N} & \ldots & 0 & -\sqrt{\beta_2 p_2} & 0 & -\sqrt{\beta_1 p_1} & R \gf + p_0 H 
\end{array} \right)
\end{equation}
and
\begin{equation}
M^{\dagger} = \left( \begin{array}{cccccccc}
-H & \sqrt{\beta_N q_N}& \ldots & 0 & 0 & 0 & 0 & 0 \\
\sqrt{\beta_N q_N} & \beta_N H & \ldots & 0 & 0 & 0& 0 & -\sqrt{\beta_N p_N } \\
 0  &  0  &  \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0  &  0  & \ldots  & -H  & \sqrt{\beta_2 q_2} & 0 & 0 &  0 \\
 0  &  0  & \ldots  & \sqrt{\beta_2 q_2} & \beta_2 H & 0 & 0 & -\sqrt{\beta_2 p_2} \\
 0  &  0  & \ldots &         0        &  0 & -H & \sqrt{\beta_1 q_1} & 0 \\
 0  &  0  & \ldots &         0        &  0 & \sqrt{\beta_1 q_1} & \beta_1 H & -\sqrt{\beta_1 p_1} \\
 0  & \sqrt{\beta_N p_N} & \ldots & 0 & \sqrt{\beta_2 p_2} & 0 & \sqrt{\beta_1 p_1} & R \gf + p_0 H 
\end{array} \right)
\end{equation}

The bulk determinant is: 
\begin{equation}
\det(A) = \prod(A_i) = (-1)^{N} \prod_{i=1}^{N} \beta_i ( H^2 + q_{i} )
\end{equation}

\section{Block Diagonalisation of the Generalised Operator and PV Matrices}
By construction, our more general matrix can be block diagonalised
in exactly the same way as the original. 

We define:
\begin{equation}
M = L \tilde{D} U
\end{equation}

with $L$, $D$ and $U$ defined as in eq (\ref{eq:LDU1}) and (\ref{eq:LDU2}).
We can then define a Pauli-Villars matrix to cancel the bulk determinant
as 
\begin{equation}
M_{PV} = L \tilde{D}_{PV} U
\end{equation}
with
\begin{equation}
\tilde{D}_{PV} = \left( \begin{array}{cc} 
 A & 0 \\
 0 & 1 
\end{array} \right)
\end{equation}

In this case:
\begin{eqnarray}
M ( M_{PV} )^{-1} &=& L \tilde{D} U \left( L \tilde{D}_{PV} U \right)^{-1} \\
&=& L \tilde{D} \tilde{D}_{PV}^{-1} L^{-1} \\
&=& L \left( \begin{array}{cc} 
 1 & 0 \\
 0 & S 
\end{array} \right) L^{-1}
\end{eqnarray}
The fermion bilinear then becomes:
\begin{eqnarray}
\bar{\Psi} M ( M_{PV} )^{-1} \Psi &=& \bar{\Psi} L \left( \begin{array}{cc} 
 1 & 0 \\
 0 & S 
\end{array} \right) L^{-1} \Psi \\
&=& \bar{\Omega} \left( \begin{array}{cc} 
 1 & 0 \\
 0 & S 
\end{array} \right) \Omega \\
&=& \bar{\omega}_0 S \omega_0 
\end{eqnarray}
 and we can see that the bulk contributions are cancelled not just in 
the determinant but the operator itself. The operator $M\left(M_{PV}\right)^{-1}$ is actually our 4D chiral operator.

Unfortunately there is a fly in the ointment:
\begin{eqnarray}
M_{PV} = L \tilde{D}_{PV} U &=&
\left( \begin{array}{cc}
1 & 0 \\
CA^{-1} & 1
\end{array} \right)
\left( \begin{array}{cc}
A & 0 \\
0 & 1 
\end{array} \right)
\left( \begin{array}{cc}
 1 & A^{-1} B \\
 0 & 1
\end{array} \right) \\
&=& \left( \begin{array}{cc} 
A & B \\
C & 1 + CA^{-1}B
\end{array}\right) \\
&=& \left( \begin{array}{cc} 
A & B \\
C & D+1-S
\end{array}\right)
\end{eqnarray}
and so, to form the PV operator $M_{PV}$ we would need to evaluate 
the Schur complement itself. In a code this would entail a multi mass solve
to apply the PV matrix (just as one is needed in evaluating the 4D partial 
fraction overlap operator).

If we are willing to relax the requirement that $M ( M_{PV})^{-1}$ give
us back the effective 4D operator and are consistent just to cancel 
the determinant, all we really need is
\begin{equation}
M'_{PV} = \tilde{D}_{PV}
\end{equation}

In this case,  $M ( M'_{PV})^{-1}$ is no longer our effective 4D operator,
however
\begin{equation}
\det\left( M ( M'_{PV})^{-1} \right) = \det(M) / \det(M'_{PV}) = \det(A)\det(S)/\det(A) = \det(S)
\end{equation}

\section{Implementation with General Moebius Kernel}
Until now we have contented ourselves with just writing the Kernel as either
$H_W$ or $H$ saying that we can put whatever we like in there. Let us now
consider the general case where 
\begin{equation}
H = (b_5 + c_5) H_W ( 2 + (b_5 - c_5)D_W )^{-1}
\end{equation}
which is the general Moebius kernel. To simplify notation we define
\begin{eqnarray}
\alpha &=& (b_5 + c_5) \\
a_5      &=& (b_5 -c_5) \ .
\end{eqnarray}
$H$ then reduces to
\begin{equation}
H = \alpha H_W ( 2 + a_5 D_W )^{-1} = \alpha H_W Q^{-1}
\end{equation}
where we have introduced 
\begin{equation}
Q = ( 2 + a_5 D_W )
\end{equation}
to which we will refer as ``the denominator piece''.

We are trying to solve the system:
\begin{equation}
M \phi = \chi
\end{equation}
by some means. We can write this as
\begin{equation}
M Q Q^{-1} \phi = \chi
\end{equation}
we can do this with a two step process:
\begin{eqnarray}
M'\phi' = (M Q) \phi' &=& \chi \\
\phi = Q \phi' \ , 
\end{eqnarray}
in other words, we perform a solve using the matrix $M'=MQ$
and we attain the solution to the system by a single application
of $Q$ (which involves no inversions -- has a constant cost).

The matrix that is needed in the solve is
\begin{equation}
M' = \left( \begin{array}{cccccccc}
-\alpha H_W & \sqrt{\beta_N q_N}Q& \ldots & 0 & 0 & 0 & 0 & 0 \\
\sqrt{\beta_N q_N}Q & \beta_N \alpha H_W & \ldots & 0 & 0 & 0& 0 & \sqrt{\beta_N p_N } Q\\
 0  &  0  &  \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0  &  0  & \ldots  & -\alpha H_W  & \sqrt{\beta_2 q_2}Q & 0 & 0 &  0 \\
 0  &  0  & \ldots  & \sqrt{\beta_2 q_2}Q & \beta_2 \alpha H_W & 0 & 0 & \sqrt{\beta_2 p_2}Q \\
 0  &  0  & \ldots &         0        &  0 & -\alpha H_W & \sqrt{\beta_1 q_1}Q & 0 \\
 0  &  0  & \ldots &         0        &  0 & \sqrt{\beta_1 q_1}Q & \beta_1 \alpha H_W & \sqrt{\beta_1 p_1}Q \\
 0  & -\sqrt{\beta_N p_N}Q & \ldots & 0 & -\sqrt{\beta_2 p_2}Q & 0 & -\sqrt{\beta_1 p_1} Q & R \gf Q + p_0 \alpha H_W 
\end{array} \right)
\end{equation}
with corresponding Hermitian conjugate:
\begin{equation}
M'^{\dagger} = \left( \begin{array}{cccccccc}
-\alpha H_W & \sqrt{\beta_N q_N}Q^{\dagger}& \ldots & 0 & 0 & 0 & 0 & 0 \\
\sqrt{\beta_N q_N}Q^{\dagger} & \beta_N \alpha H_W & \ldots & 0 & 0 & 0& 0 & -\sqrt{\beta_N p_N } Q^{\dagger}\\
 0  &  0  &  \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 0  &  0  & \ldots  & -\alpha H_W  & \sqrt{\beta_2 q_2}Q^{\dagger} & 0 & 0 &  0 \\
 0  &  0  & \ldots  & \sqrt{\beta_2 q_2}Q^{\dagger} & \beta_2 \alpha H_W & 0 & 0 & -\sqrt{\beta_2 p_2}Q^{\dagger} \\
 0  &  0  & \ldots &         0        &  0 & -\alpha H_W & \sqrt{\beta_1 q_1}Q^{\dagger} & 0 \\
 0  &  0  & \ldots &         0        &  0 & \sqrt{\beta_1 q_1}Q^{\dagger} & \beta_1 \alpha H_W & -\sqrt{\beta_1 p_1}Q^{\dagger} \\
 0  & \sqrt{\beta_N p_N}Q^{\dagger} & \ldots & 0 & \sqrt{\beta_2 p_2}Q^{\dagger} & 0 & \sqrt{\beta_1 p_1} Q^{\dagger} & R Q^{\dagger} \gf + p_0 \alpha H_W 
\end{array} \right)
\end{equation}

Consider applying the operator $M'$, ie evaluating
\begin{equation}
\chi = M' \psi
\end{equation}
with $\chi=( \chi_{2N}, \chi_{2N-1}, \ldots, \chi_{2}, \chi_{1}, \chi_{0} )^{T}$ and $\psi=( \psi_{2N}, \psi_{2N-1}, \ldots, \psi_{2}, \psi_{1}, \psi_{0} )^{T}$.

We proceed as follows:
\begin{itemize}
\item
Start off with 
\begin{eqnarray}
\psi_{0} &=& (R\gf Q + p_0 \alpha H_w) \chi_0 \\
         &=& \left( \gf R ( 2 + a_5 D_W ) + p_0 \alpha \gf D_W \right) \chi_0 \\
         &=& 2 R \gf \chi_0 + \gf ( R a_5 + p_0 \alpha ) D_W \chi_0
\end{eqnarray}
\item
We can then take care of the rest of the last row of the matrix:
\begin{equation}
\psi_0 \rightarrow \psi_0 - \sum_{i=1}^{N} \sqrt{\beta_{i} p_{i}} Q \chi_{2i-1} 
\end{equation}
evaluating $  \sqrt{\beta_{i} p_{i}} Q \chi_{2i-1}$ can be done as follows:
\begin{eqnarray}
 \sqrt{\beta_{i} p_{i}} Q \chi_{2i-1} &=&  \sqrt{\beta_{i} p_{i}} ( 2 + a_5 D_W ) \chi_{2i-1} \\
 &=&  2 \sqrt{\beta_{i} p_{i}} \chi_{2i-1} + \sqrt{\beta_{i} p_{i}} a_5 D_W \chi_{2i-1}
\end{eqnarray}
\item
Finally we need to take care of the remaining rows of the matrix. For the 
$i$-th pole, we need to deal with rows $2i$ and $2i-1$.
Consider first the $2i$-th row:
\begin{eqnarray}
\psi_{2i} &=& -\alpha H_W \chi_{2i} + \sqrt{\beta_{i} q_{i}} Q \chi_{2i-1} \\
 &=& -\gf \alpha D_W \chi_{2i} + (2 + a_5 D_W)  \sqrt{\beta_{i} q_{i}}\chi_{2i-1} \\
 &=& 2 \sqrt{\beta_{i} q_{i}}\chi_{2i-1} + a_5 \sqrt{\beta_{i} q_{i}} D_W \chi_{2i-1} - \gf \alpha D_W \chi_{2i}
\end{eqnarray}
Second we consider the $2i-1$-th row
\begin{eqnarray}
\psi_{2i-1} &=& \sqrt{ \beta_{i} q_i } Q \chi_{2i} + \beta_i \alpha H_W \chi_{2i-1} + \sqrt{\beta_i p_i} Q \chi_{0} \\
 &=&  \sqrt{ \beta_{i} q_i } (2 + a_5 D_W) \chi_{2i} +  \beta_i \alpha \gf D_W \chi_{2i-1}  + \sqrt{\beta_i p_i} (2 + a_5 D_W) \chi_{0} \\
 &=& 2 ( \sqrt{ \beta_{i} q_i } \chi_{2i} + \sqrt{\beta_i p_i} \chi_0 ) + a_5 (  \sqrt{ \beta_{i} q_i } D_W \chi_{2i} +  \sqrt{\beta_i p_i} D_W \chi_0 )\nonumber \\   &+&  \beta_i \alpha \gf D_W \chi_{2i-1}
\end{eqnarray}
\end{itemize}
Note that all the steps above make reference to vectors $\chi_i$ and $D_W \chi_i$. So we can precompute $t_{i} = D_W \chi_i$ up front and use its elements
as needed.

The primary cost of applying the operator is then $2N+1=N_5$ applications of $D_W$.

Applying the conjugate is straightforward also. However there is a subtlety.
The $D_W$ in $Q$ will become $D_W^{\dagger}$ in $Q^{\dagger}$, but $H_W$ is
Hermitian. However there is nothing to stop it from being written as
$H = D^{\dagger} \gf$. The procedure then becomes

\begin{itemize}
\item
Start off with
\begin{eqnarray}
\psi_{0} &=& (R Q^{\dagger} \gf + p_0 \alpha H_w) \chi_0 \\
         &=& \left( R ( 2 + a_5 D_W^{\dagger} ) \gf  + p_0 \alpha D_W^{\dagger} \gf \right) \chi_0 \\
         &=& 2 R \gf \chi_0 +  D_W^{\dagger} \left[ ( R a_5 + p_0 \alpha ) \gamma_5 \chi_0 \right]
\end{eqnarray}
\item
We can then take care of the rest of the last row of the matrix:
\begin{equation}
\psi_0 \rightarrow \psi_0 + \sum_{i=1}^{N} \sqrt{\beta_{i} p_{i}} Q^{\dagger} \chi_{2i-1} 
\end{equation}
evaluating $  \sqrt{\beta_{i} p_{i}} Q^{\dagger} \chi_{2i-1}$ can be done as follows:
\begin{eqnarray}
 \sqrt{\beta_{i} p_{i}} Q^{\dagger} \chi_{2i-1} &=&  \sqrt{\beta_{i} p_{i}} ( 2 + a_5 D_W^{\dagger} ) \chi_{2i-1} \\
 &=&  2 \sqrt{\beta_{i} p_{i}} \chi_{2i-1} + D_W^{\dagger} \left[ \sqrt{\beta_{i} p_{i}} a_5 \chi_{2i-1} \right]
\end{eqnarray}
(Note that the conjugation has changed the subtraction in $M'$ into an
addition in $M'^{\dagger}$. In a hermitian version this complication
would not arise.
\item
Finally we need to take care of the remaining rows of the matrix. For the 
$i$-th pole, we need to deal with rows $2i$ and $2i-1$.
Consider first the $2i$-th row:
\begin{eqnarray}
\psi_{2i} &=& -\alpha H_W \chi_{2i} + \sqrt{\beta_{i} q_{i}} Q^{\dagger} \chi_{2i-1} \\
 &=& - \alpha D_W^{\dagger} \gf \chi_{2i} + (2 + a_5 D_W^{\dagger} )  \sqrt{\beta_{i} q_{i}}\chi_{2i-1} \\
 &=& 2 \sqrt{\beta_{i} q_{i}}\chi_{2i-1} + D_W^{\dagger} \left[ a_5 \sqrt{\beta_{i} q_{i}} \chi_{2i-1} - \gf \alpha \chi_{2i} \right]
\end{eqnarray}
Second we consider the $2i-1$-th row
\begin{eqnarray}
\psi_{2i-1} &=& \sqrt{ \beta_{i} q_i } Q^{\dagger} \chi_{2i} + \beta_i \alpha H_W \chi_{2i-1} - \sqrt{\beta_i p_i} Q^{\dagger}  \chi_{0} \\
 &=&  \sqrt{ \beta_{i} q_i } (2 + a_5 D_W^{\dagger} ) \chi_{2i} +  \beta_i \alpha  D_W^{\dagger} \gf \chi_{2i-1}  - \sqrt{\beta_i p_i} (2 + a_5 D_W^{\dagger}) \chi_{0} \\
 &=& 2 ( \sqrt{ \beta_{i} q_i } \chi_{2i} - \sqrt{\beta_i p_i} \chi_0 ) +  D_W^{\dagger}  \left[  a_5 \sqrt{ \beta_{i} q_i } \chi_{2i} -  a_5 \sqrt{\beta_i p_i} \chi_0 \nonumber \right. \\   &+&  \left. \beta_i \alpha \gf  \chi_{2i-1} \right]
\end{eqnarray}
\end{itemize}
One can see that the $\psi_i$ are always made up of two parts. A part that
contains only the $\chi_i$ and coefficients and a part that is pre--multiplied
by $D^{\dagger}_W$ -- which I have always collected in square brackets. An 
efficient evaluation, would work out the parts in square brackets into
a temporary 5D vector, and then apply $D_W^{\dagger}$ to each element 
of the temporary. The $\psi$ vector can then be assembled. 

Thus applying $M^{\dagger}$ costs the same amount of matrix multiplications
as $M$.

\section{Preconditioning The Operator}
Making virtue of the fact that we can write $D_W$ on preconditioned
form -- acting on vectors $(\psi_o, \psi_e )$ :
\begin{eqnarray}
D_W &=& (N_d - M) - \frac{1}{2} D_s \\
    &=& \left( \begin{array}{cc} 
      N_d - M & -\frac{1}{2} D_s^{oe} \\
      -\frac{1}{2} D_s^{eo} & N_d - M 
    \end{array}\right) \ ,
\end{eqnarray}
we can decompose $M'$ into an odd-even form in 4D.
\begin{equation}
M' = \left( \begin{array}{cc} 
      M^{oo} & M^{oe} \\
      M^{eo} & M^{ee} \ .
\end{array} \right)
\end{equation}
The matrix $M$ now acts on 5D vectors written 
as 
\begin{equation}
\psi = \left( \psi_{o}^{2n}, \psi_{o}^{2n-1}, \ldots, \psi_{o}^{1}, \psi_{o}^0, \psi_{e}^{2n}, \psi_{e}^{2n-1}, \ldots, \psi_{e}^{1}, \psi_{e}^0 \right)^{T} \\
\end{equation}
with $\psi_{e}^{i}$ and $\psi_{o}^{i}$ etc are 4D half vectors.

The even odd preconditioned matrices are:
\begin{equation}
M^{ee}=\left( \begin{array}{cccccc}
-\alpha \tilde{P} \gf & \sqrt{\beta_N q_N}\tilde{Q} & \ldots & 0 & 0 & 0 \\
\sqrt{\beta_N q_N}\tilde{Q} & \beta_N \alpha \tilde{P}\gf & \ldots & 0 & 0 & \sqrt{\beta_N p_N}\tilde{Q} \\
 0 & 0 & \vdots & \vdots & \vdots & \vdots  \\
0 & 0 & \ldots & -\alpha \tilde{P} \gf & \sqrt{\beta_1 q_1}\tilde{Q} & 0 \\
0 & 0 & \ldots & \sqrt{\beta_1 q_1}\tilde{Q} & \alpha \tilde{P} \gf &  \sqrt{\beta_1 p_1}\tilde{Q} \\
0 & -\sqrt{\beta_N p_N}\tilde{Q}& \ldots & 0 & -\sqrt{\beta_N p_N}\tilde{Q} & \left( R \tilde{Q} + p_0 \alpha \tilde{P} \right)\gf
\end{array} \right)
\end{equation}
where we have introduced the {\em numbers}
\begin{equation}
\tilde{P} = N_d - M, \qquad \tilde{Q} = 2 + a_5(N_d-M)
\end{equation}
The hermitian conjugate is just the transpose:
\begin{equation}
M^{ee \dagger}=\left( \begin{array}{cccccc}
-\alpha \tilde{P} \gf & \sqrt{\beta_N q_N}\tilde{Q} & \ldots & 0 & 0 & 0 \\
\sqrt{\beta_N q_N}\tilde{Q} & \beta_N \alpha \tilde{P}\gf & \ldots & 0 & 0 & -\sqrt{\beta_N p_N}\tilde{Q} \\
 0 & 0 & \vdots & \vdots & \vdots & \vdots  \\
0 & 0 & \ldots & -\alpha \tilde{P} \gf & \sqrt{\beta_1 q_1}\tilde{Q} & 0 \\
0 & 0 & \ldots & \sqrt{\beta_1 q_1}\tilde{Q} & \alpha \tilde{P} \gf &  -\sqrt{\beta_1 p_1}\tilde{Q} \\
0 & \sqrt{\beta_N p_N}\tilde{Q}& \ldots & 0 & \sqrt{\beta_N p_N}\tilde{Q} & \left( R \tilde{Q} + p_0 \alpha \tilde{P} \right)\gf
\end{array} \right)
\end{equation}
Further, $M^{oo}=M^{ee}$ by which I mean that the matrix
entries are the same, but of course $M^{oo}$ acts only on the 
odd half-vectors.

Similarly:
\begin{equation}
M^{oe} = \left( \begin{array}{cccccc}
\frac{\alpha}{2}\gf D^{oe}_s & -\sqrt{\beta_N q_N}\frac{a_5}{2} D^{oe}_s & \ldots & 0 & 0 & 0 \\
 -\sqrt{\beta_N q_N}\frac{a_5}{2} D^{oe}_s & -\frac{\beta_N \alpha}{2}\gf D^{oe}_s & \ldots & 0 & 0 & -\sqrt{\beta_N p_N}\frac{a_5}{2} D^{oe}_s \\
0 & 0 & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots &  \frac{\alpha}{2} \gf D^{oe}_s & -\sqrt{\beta_1 q_1}\frac{a_5}{2}D^{oe}_s & 0 \\
0 & 0 & \ldots &  -\sqrt{\beta_1 q_1}\frac{a_5}{2} D^{oe}_s &  -\frac{\beta_1 \alpha}{2}\gf D^{oe}_s & -\sqrt{\beta_1 p_1}\frac{a_5}{2} D^{oe}_s \\
0 &  \sqrt{\beta_N p_N}\frac{a_5}{2} D^{oe}_s & \ldots & 0 &  \sqrt{\beta_1 p_1}\frac{a_5}{2} D^{oe}_s & -\frac{R a_5 + p_0 \alpha}{2} \gf D_s^{oe}
\end{array} \right)
\end{equation}
and the Hermitian Conjugate is:
\begin{equation}
M^{oe} = \left( \begin{array}{cccccc}
\frac{\alpha}{2} D^{oe\dagger}_s \gf  & -\sqrt{\beta_N q_N}\frac{a_5}{2} D^{oe\dagger}_s & \ldots & 0 & 0 & 0 \\
 -\sqrt{\beta_N q_N}\frac{a_5}{2} D^{oe\dagger}_s & -\frac{\beta_N \alpha}{2} D^{oe\dagger}_s \gf& \ldots & 0 & 0 & \sqrt{\beta_N p_N}\frac{a_5}{2} D^{oe\dagger}_s \\
0 & 0 & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots &  \frac{\alpha}{2} D^{oe\dagger}_s \gf & -\sqrt{\beta_1 q_1}\frac{a_5}{2} D^{oe\dagger}_s & 0 \\
0 & 0 & \ldots &  -\sqrt{\beta_1 q_1}\frac{a_5}{2}D^{oe\dagger }_s &  -\frac{\beta_1 \alpha}{2}D^{oe \dagger}_s\gf & \sqrt{\beta_1 p_1}\frac{a_5}{2} D^{oe \dagger}_s \\
0 &  -\sqrt{\beta_N p_N}\frac{a_5}{2} D^{oe\dagger}_s & \ldots & 0 &  -\sqrt{\beta_1 p_1}\frac{a_5}{2} D^{oe\dagger }_s & -\frac{R a_5 + p_0 \alpha}{2} D_s^{oe \dagger} \gf
\end{array} \right)
\end{equation}

Evaluating $M^{oe}$ and $M^{oe\dagger}$ can be done using only $2N+1=L_s$ 
applications of $D^{oe}_s$ by using similar tricks to the unpreconditioned
case, namely for the case of $M^{oe}$, to construct a temporary vector 
of $t_i = D^{oe}_s \chi_{i}$ for all ${i}$, whereas for the case of the
$M^{oe\dagger}$ we use the temporary to perform the arithmetic involved
without applying the $D^{oe\dagger}_{s}$ {\em on the source checkerboard}
and then applying $D^{oe\dagger}$ to the each element of the temporary 
vector at the end. $M^{eo}$ can be obtained from $M^{oe}$ by replacing
$D^{oe}$ with $D^{eo}$ everywhere. Likewise for the hermitian conjugate.

The preconditioning now comes from applying the Schur decomposition
on the even-odd indices:
\begin{equation}
\left( \begin{array}{cc}
M^{oo} & M^{oe} \\
M^{eo} & M^{ee}
\end{array} \right) = \left( \begin{array}{cc}
                                 1   &   0  \\
                               M^{eo}(M^{oo})^{-1} & 1 
                      \end{array} \right) 
                      \left( \begin{array}{cc}
                               M^{oo} &  M^{oe} \\
                                 0    & M^{ee} - M^{eo}(M^{oo})^{-1}M^{oe} \\
                      \end{array} \right)
\end{equation}
Inversions can then be done (in this case) on the even subset, and the 
solution on the odd subset can be reconstructed. It can clearly be
seen that in order for this to work, one needs to be able to apply
$(M^{oo})^{-1}$. We now discuss how this can be done efficiently.

We first of all rewrite $M^{oo}$ as
\begin{equation}
M^{oo} = \left( \begin{array}{ccccc|c}
a  \gf & b_N & \ldots & 0 & 0 & 0 \\
b_N     & d_N \gf & \ldots & 0 & 0 & c_N \\
 0      &  0  & \vdots & \vdots & \vdots& \vdots \\
 0      &  0  & \ldots & a \gf & b_1  & 0 \\
 0      &  0  & \ldots & b_1    & d_1 \gf & c_1 \\
\hline
 0      & -c_N & \ldots & 0     & -c_1 &  e \gf 
\end{array}\right) 
\end{equation}
with
\begin{eqnarray}
a   &=& -\alpha \tilde{P} = -\alpha(N_d-M) \\
b_i &=& \sqrt{\beta_i q_i}\tilde{Q} = \sqrt{\beta_i q_i}(2 + a_5(N_d-M)) \\
c_i &=& \sqrt{\beta_i p_i}\tilde{Q} = \sqrt{\beta_i q_i}(2 + a_5(N_d-M)) \\
e &=& R\tilde{Q} + p_0\alpha\tilde{P} = 2R + ( a_5 R + p_0\alpha )(N_d-M))
\end{eqnarray}

These constants can be computed at the construction of the operator. 
They do not depend on the gauge fields.

We then write $M^{oo}$ in the block form:
\begin{equation}
M^{oo} = \left( \begin{array}{cc} 
  \tilde{A} & \tilde{C} \\
  -\tilde{C}^{T} & \tilde{E} 
\end{array}\right)
\end{equation}
with
\begin{eqnarray}
\tilde{A} &=& \left( \begin{array}{ccccc}
 a \gf & b_N & \ldots & 0 & 0 \\
 b_N & d_N \gf & \ldots & 0 & 0 \\
 0   &  0  & \vdots & \vdots & \vdots \\
 0   &  0 & \ldots & a \gf & b_1  \\
 0   &  0 & \ldots & b_1   & d_1 \gf 
\end{array} \right) = \mbox{diag}(\tilde{A}_N, \tilde{A}_{N-1},\ldots, \tilde{A}_1) \\
\tilde{C} &=& \left( \begin{array}{c} 
\tilde{C}_N \\
\vdots \\
\tilde{C}_1
\end{array} \right), \quad \mbox{with} \ \tilde{C}_i = \left(0,c_i\right)^T \\
\tilde{E} &=& e\gf
\end{eqnarray}
In the above we have made the implicit definition
\begin{equation}
\tilde{A}_i 
= \left( \begin{array}{cc} a\gf & b_i \\ b_i & d_i \gf \end{array} \right)
\end{equation}

We now apply the Schur Decomposition to $M^{oo}$
\begin{equation}
M^{oo} = \left( \begin{array}{cc} 
1 & 0 \\
-\tilde{C}^T \tilde{A}^{-1} & 1 
\end{array} \right)
\left( \begin{array}{cc} 
 \tilde{A} & 0 \\
           & \tilde{E} + \tilde{C}^{T}\tilde{A}^{-1}\tilde{C} 
\end{array} \right)
\left(\begin{array}{cc}
1 & \tilde{A}^{-1} \tilde{C} \\ 
0 &  1 
\end{array}\right) = \tilde{L} \tilde{D} \tilde{U} \ .
\end{equation}


Now consider applying $M^{-1}$ to some vector $\chi$:
\begin{eqnarray}
 \psi &=& M^{-1}\chi \\
\tilde{D} \tilde{U} \psi &=& \tilde{L}^{-1} \chi = \chi'
\end{eqnarray}
We need to
\begin{itemize}
\item
form $\chi'$. This can be done by solving
\begin{equation}
\tilde{L} \chi' = \chi
\end{equation} 
using forward substitution
\item
Solve 
\begin{equation}
\tilde{D} \psi' = \chi'
\end{equation}
which can be done by explicitly directly inverting $\tilde{D}$.
\item
finally we need to find
\begin{equation}
\psi = \tilde{U}^{-1} \psi'
\end{equation}
which can be done by solving
\begin{equation}
\tilde{U} \psi = \psi'
\end{equation}
using backsubstitution.
\end{itemize}

Let us consider the inverse of $\tilde{A}$. We can invert each subblock
explicitly:
\begin{equation}
\tilde{A}^{-1}_i = \left(
\begin{array}{cc}
a \gf & b_i \\
b_i & d_i \gf
\end{array} \right)^{-1} 
= \frac{1}{a d_i - b^{2}_i} \left( \begin{array}{cc}
d_i \gf & -b_i \\
-b_i &  a \gf 
\end{array} \right) = 
\left( \begin{array}{cc}
 d'_i \gf & -b'_i \\
-b'_i & a'_i \gf \\
\end{array} \right)
\end{equation}
Here we have introduced:
\begin{equation}
a'_i = \frac{a}{a d_i - b^2_i}, \quad
b'_i = \frac{b_i}{a d_i - b^2_i}, \quad
d'_i = \frac{d_i}{a d_i - b^2_i}
\end{equation}
which can all be precomputed when we initialise the matrix.

Using these we can now explictly form $\tilde{A}^{-1}\tilde{C}$ and
also $\tilde{E} + \tilde{C}^{T}\tilde{A}^{-1} \tilde{C}$.
\begin{equation}
\tilde{A}_i^{-1} \tilde{C}_{i} =  \left( \begin{array}{cc}
 d'_i \gf & -b'_i \\
-b'_i & a'_i \gf \\
\end{array} \right) \left( \begin{array}{c}
 0 \\
c_i \\
\end{array} \right) = \left( \begin{array}{c} 
-b'_i c_i \\
a'_i c_i \gf 
\end{array} \right)
\end{equation}
and
\begin{equation}
\tilde{C}_i^{T} \tilde{A}^{-1}_i \tilde{C}_i = \left( 0, c_i \right) \left( \begin{array}{c}
-b'_i c_i \\
a'_i c_i \gf 
\end{array} \right) = a'_i c^{2}_i \gf
\end{equation}
So the Schur's complement $\tilde{E} + \tilde{C}_i^{T} \tilde{A}^{-1}_i \tilde{C}_i$ is
\begin{equation}
\tilde{E} + \tilde{C}_i^{T} \tilde{A}^{-1}_i \tilde{C}_i = \left( e + \sum_{i=1}^{N} a'_i c^{2}_i \right) \gf = \tilde{S} \gf
\end{equation}
where we have introduced $\tilde{S}$ as the Schur's complement of the coefficients only. The matrix $\tilde{U}$ is 
\begin{equation}
\tilde{U} = \left( \begin{array}{cccccccc} 
1 & 0 & \ldots & 0 & 0 & 0 & 0 & -b'_N c_N \\
0 & 1 & \ldots & 0 & 0 & 0 & 0 &  a'_N c_N \gf \\
0 & 0 & \vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots & 1 & 0 & 0 & 0 & -b'_2 c_2 \\
0 & 0 & \ldots & 0 & 1 & 0 & 0 &  a'_2 c_2 \gf \\
0 & 0 & \ldots & 0 & 0 & 1 & 0 & -b'_1 c_1 \\
0 & 0 & \ldots & 0 & 0 & 0 & 1 &  a'_1 c_1 \gf \\
0 & 0 & \ldots & 0 & 0 & 0 & 0 &     1
\end{array} \right)
\end{equation}
and $\tilde{L}$ is 
\begin{equation}
\tilde{U} = \left( \begin{array}{cccccccc} 
1 & 0 & \ldots & 0 & 0 & 0 & 0 & 0  \\
0 & 1 & \ldots & 0 & 0 & 0 & 0 &  0 \\
0 & 0 & \vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots & 1 & 0 & 0 & 0 &  0 \\
0 & 0 & \ldots & 0 & 1 & 0 & 0 &  0 \gf \\
0 & 0 & \ldots & 0 & 0 & 1 & 0 &  0 \\
0 & 0 & \ldots & 0 & 0 & 0 & 1 &  0 \gf \\
b'_N c_N & -a'_N c_N \gf & \ldots & b'_2 c_2 & -a'_2 c_2 \gf  & b'_1 c_1 & -a'_1 c_1 \gf &     1
\end{array} \right)
\end{equation}
We should note that when working with the Hermitian Conjugate of 
$M^{oo}$ merely flips the signs of the non-zero, non-unit 
elements of $\tilde{U}$ and $\tilde{L}$. These elements 
can also all be precomputed at the creation of the matrix.

So on initialisation we need to:
\begin{itemize}
\item
Compute $a$, $b_i$, $d_i$, $c_i$ and $e$.
\item
Compute the coefficients of the inverses: $a'_i$, $b'_i$, $d'_i$.
\item
Compute the non-zero, non-unit coefficients of $\tilde{L}$ and $\tilde{U}$: $a'_i c_i$ and $b'_i c_i$.
\item
Compute the Schur's complement of the coefficients: $\tilde{S} = \left( e + \sum_{i=1}^{N} a'_i c^{2}_i \right)$
\end{itemize}

To invert $M^{oo}$ we need to 
\begin{itemize}
\item
Forward subsitute with $\tilde{L}$, using its elements with the appropriate
sign.
\item
Apply the inverse of $\tilde{D}$. This is easy. We apply the inverse blocks
$\tilde{A}^{-1}_i$ for all the poles, then at the end we use
\begin{equation}
(\tilde{S}\gf)^{-1} = \frac{1}{\tilde{S}} \gf
\end{equation}
\item
Finally we backsubstitute with $\tilde{U}$ using its precomputed
elements with the appropriate signs.
\end{itemize}

\section{Implementation notes}
\subsection{Tuning strategies}
In our implementation we employ three possible tuning strategies for
the $\beta_i$ coefficients.
\begin{itemize}
\item
$\beta_i=c$ for some constant c. This sets nonzero elements of the
rightmost column, and bottom row equal to $\sqrt{p_i c}$ in absolute value.
\item 
$\beta_i=\frac{1}{c p_i}$ for some constant c. This sets the nonzero
elements of the rightmost column and bottom row equal to $ \frac{1}{\sqrt{c}}$,
making them $p_i$ independent.
\item
$\beta_i=\frac{1-\mu}{2 p_i}$ -- this sets the nonzero elements of the 
rightmost column and the bottom row equal to $\sqrt{\frac{1-\mu}{2}}$ 
mimicking the original operator of \cite{NeubergerNarayanan}. It is
not exactly the same tho, due to our rescaling of the mass term.
\end{itemize}

My preliminary experiences suggested that the last of these strategies
performed uniformly well.

\subsection{Approximations and rescaling bounds}
In our implementation we allow the selection of coefficients from either
Zolotarev's approximation or from the Higham-tanh approximation the 
latter being the same used in \cite{NeubergerNarayanan} up to a possible
factor of $\frac{1}{n}$. In the case of the Higham represenation, the 
scaling constant $\alpha$ in the Moebius kernel can be chosen arbitrarily.

In the case of the Zolotarev approximation, it is pointless to choose
any value of $\alpha$ other than the naive choice. For the case of 
$a_5=0$ the naive choice is $\alpha=2 \iff b_5=c_5=1$. The factor
of 2 from $\alpha$ is cancelled by the denominator piece, leading
to the naive $H=H_W$. In this case the domain of the Zolotarev
approximation should be over the bounds of the eigenspectrum of $H_W$.

For the case of $a_5 = 1$, the naive choice is $\alpha=1 \iff b_5 =1, c5=0$.
In this case the approximation domain should be over the eigenspectrum
of 
$$
H_T = H_W \frac{ 1 }{2 + a_5 D_W}
$$
ie the usual Domain-Wall transfer matrix Hamiltonian.

If the scale factor was different from the naive choice, when using
the Zolotarev coefficients, the coefficients could be rescaled
to accomodate the non-trivial scale factor. However, the rescaling
is different for the two cases of the Kernel. Hence in our 
implementation, if you use Zolotarev coefficients, and not the 
naive values of $\alpha$, the bounds you should enter for the 
approximation should be scaled appropriately in your input file.
The code does not deal with this automatically.


\begin{thebibliography}{99}
\bibitem{NeubergerNarayanan}
R.~Narayanan, H~Neuberger, Phys. Rev. D62(2000) 074504, \htmladdnormallink{\tt hep-lat/0005004}{http://arxiv.org/abs/hep-lat/0005004}
\end{thebibliography}

\end{document}